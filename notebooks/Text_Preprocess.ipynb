{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "posts_df = pd.read_csv('../data/interum/stack_overflow_with_targets.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111102</td>\n",
       "      <td>&lt;p&gt;How would you explain JavaScript closures t...</td>\n",
       "      <td>javascript|scope|closures</td>\n",
       "      <td>\\n\\nHow would you explain JavaScript closures ...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1642028</td>\n",
       "      <td>&lt;p&gt;After reading &lt;a href= http://groups.google...</td>\n",
       "      <td>c++|c|operators|code-formatting|standards-comp...</td>\n",
       "      <td>\\n\\nAfter reading Hidden Features and Dark Cor...</td>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               body  \\\n",
       "0   111102  <p>How would you explain JavaScript closures t...   \n",
       "1  1642028  <p>After reading <a href= http://groups.google...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                          javascript|scope|closures   \n",
       "1  c++|c|operators|code-formatting|standards-comp...   \n",
       "\n",
       "                                                text      target  \n",
       "0  \\n\\nHow would you explain JavaScript closures ...  javascript  \n",
       "1  \\n\\nAfter reading Hidden Features and Dark Cor...         c++  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocesss:\n",
    "* converting all letters to lower or upper case\n",
    "* converting numbers into words or removing numbers\n",
    "* removing white spaces\n",
    "* removing punctuations, accent marks and other diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep necessary columns\n",
    "text_target = posts_df[['text','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(post):\n",
    "    '''\n",
    "    input:\n",
    "    post: a string with symbols and punctuations \n",
    "    returns:\n",
    "    cleaned post with all letters to lower, all numbers, white space, and symbols removed\n",
    "    '''\n",
    "    pattern = r'[^A-Za-z]+' # anything that is not letter or space \n",
    "    processed = re.sub(pattern, ' ', post).strip().lower()\n",
    "    return processed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_target['text'] = text_target.text.apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* removing stop words, sparse terms, and particular words\n",
    "* lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position tags function to word_net postition tag \n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def token_lemma(post):\n",
    "    '''\n",
    "    input:\n",
    "    post: cleaned post from function text_preprocess\n",
    "    returns:\n",
    "    tokenized post with lemmatization with position tags\n",
    "    stopwords and tags are removed \n",
    "    '''\n",
    "    tokens = word_tokenize(post)\n",
    "    # stopwords\n",
    "    stop_words = set(stopwords.words('english'))  # make sure no repeats\n",
    "    # remove stopwords and remove words that are explicit tags\n",
    "    words_to_remove = set(text_target.target.unique()).union(stop_words)\n",
    "    # perform pos tag before stop word removal to include more context for pos tags \n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags_word_net = [get_wordnet_pos(w[1]) for w in tags]\n",
    "    lem_result = []  # only include nonstop words and target tags \n",
    "    for i in range(len(tags_word_net)):\n",
    "        if tags[i][0] in words_to_remove:  # don't lemmatize unneeded words \n",
    "            continue\n",
    "        if tags_word_net[i]:  # not none \n",
    "            lem_result.append(lemmatizer.lemmatize(tags[i][0],tags_word_net[i]))\n",
    "        else:\n",
    "            lem_result.append(tags[i][0])\n",
    "    return lem_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to text \n",
    "text_target['text'] = text_target.text.apply(token_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, explain, closure, someone, knowledge, ...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[read, hidden, feature, dark, corner, c, stl, ...</td>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[redirect, user, one, page, another, use, jquery]</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[use, yield, keyword, example, try, understand...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[check, one, string, contain, another, substri...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      target\n",
       "0  [would, explain, closure, someone, knowledge, ...  javascript\n",
       "1  [read, hidden, feature, dark, corner, c, stl, ...         c++\n",
       "2  [redirect, user, one, page, another, use, jquery]  javascript\n",
       "3  [use, yield, keyword, example, try, understand...      python\n",
       "4  [check, one, string, contain, another, substri...  javascript"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_target.to_pickle('../data/interum/text_target.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
