{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import uniform\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_pickle('../data/interum/text_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111102</td>\n",
       "      <td>&lt;p&gt;How would you explain JavaScript closures t...</td>\n",
       "      <td>javascript|scope|closures</td>\n",
       "      <td>\\n\\nHow would you explain JavaScript closures ...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>would explain closure someone knowledge concep...</td>\n",
       "      <td>[would, explain, closure, someone, knowledge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1642028</td>\n",
       "      <td>&lt;p&gt;After reading &lt;a href= http://groups.google...</td>\n",
       "      <td>c++|c|operators|code-formatting|standards-comp...</td>\n",
       "      <td>\\n\\nAfter reading Hidden Features and Dark Cor...</td>\n",
       "      <td>c++</td>\n",
       "      <td>read hidden feature dark corner c stl comp lan...</td>\n",
       "      <td>[read, hidden, feature, dark, corner, c, stl, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               body  \\\n",
       "0   111102  <p>How would you explain JavaScript closures t...   \n",
       "1  1642028  <p>After reading <a href= http://groups.google...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                          javascript|scope|closures   \n",
       "1  c++|c|operators|code-formatting|standards-comp...   \n",
       "\n",
       "                                                text      target  \\\n",
       "0  \\n\\nHow would you explain JavaScript closures ...  javascript   \n",
       "1  \\n\\nAfter reading Hidden Features and Dark Cor...         c++   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  would explain closure someone knowledge concep...   \n",
       "1  read hidden feature dark corner c stl comp lan...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [would, explain, closure, someone, knowledge, ...  \n",
       "1  [read, hidden, feature, dark, corner, c, stl, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into features and target \n",
    "feature = posts_df['cleaned_text']\n",
    "label = posts_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    feature, label, stratify = label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidVector Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24241x57072 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 949219 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try tfidVector \n",
    "tfid_vect = TfidfVectorizer()\n",
    "tfid_vect.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and test sets \n",
    "x_train_tfidf = tfid_vect.transform(train_X)\n",
    "x_test_tfidf =tfid_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.get_feature_names of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)>\n"
     ]
    }
   ],
   "source": [
    "print(tfid_vect.get_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlaize all models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lg = LogisticRegression(random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "nb = MultinomialNB()\n",
    "# xg = XGBClassifier(random_state = 42)\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "test: [0.74285361 0.74569979 0.74811239]\n",
      "train: [0.9977104  0.99740099 0.99733944]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "test: [0.80076723 0.79940601 0.79848991]\n",
      "train: [0.88768564 0.88935644 0.89419626]\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "test: [0.72899394 0.74186363 0.70441886]\n",
      "train: [0.77475248 0.7927599  0.74433857]\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "test: [0.75559955 0.76339562 0.76667904]\n",
      "train: [0.84269802 0.84263614 0.84333622]\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=42)\n",
      "test: [0.72565277 0.72701398 0.7392004 ]\n",
      "train: [0.74690594 0.74684406 0.74248237]\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "test: [0.74186363 0.74421482 0.75628172]\n",
      "train: [0.78842822 0.78644802 0.78474199]\n"
     ]
    }
   ],
   "source": [
    "# try vanilla models \n",
    "for base_clf in (rf,lg,svc,nb,ada,gb):\n",
    "        clf = OneVsRestClassifier(base_clf)\n",
    "        cv_results = cross_validate(clf,x_train_tfidf,train_y, cv = 3,n_jobs=-1,return_train_score= True)\n",
    "        print(base_clf)\n",
    "        print('test:', cv_results['test_score'])\n",
    "        print('train:', cv_results['train_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we will focus on:\n",
    "\n",
    "* MultinomialNB\n",
    "* RandomForest\n",
    "* LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter for logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf',lg ),\n",
    "])\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C =uniform(loc=0, scale=4)\n",
    "max_df = np.linspace(0.3,0.75,num = 10)\n",
    "min_df = np.arange(1,16,2)\n",
    "max_features = np.arange(5000,10000,500)\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,1),(1,2)),\n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df':min_df,\n",
    "        'vect__max_features':max_features,\n",
    "        'clf': (lg,),\n",
    "        'clf__penalty': ('l1','l2'),\n",
    "        'clf__C': C}\n",
    "clf_lg = RandomizedSearchCV(pipeline, parameters,random_state = 42, n_iter=100, cv = 3, n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           1),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop...\n",
       "                                        'clf__penalty': ('l1', 'l2'),\n",
       "                                        'vect__max_df': array([0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75]),\n",
       "                                        'vect__max_features': array([5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500]),\n",
       "                                        'vect__min_df': array([ 1,  3,  5,  7,  9, 11, 13, 15]),\n",
       "                                        'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': LogisticRegression(C=2.343102325093853, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                    random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'clf__C': 2.343102325093853,\n",
       " 'clf__penalty': 'l1',\n",
       " 'vect__max_df': 0.45,\n",
       " 'vect__max_features': 8500,\n",
       " 'vect__min_df': 7,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127965017944804"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer search\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', lg),\n",
    "])\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,2),),\n",
    "        'vect__max_df': (0.4,0.5),\n",
    "        'vect__min_df':(6,8),\n",
    "        'vect__max_features':(8000,9000),\n",
    "        'clf': (lg,),\n",
    "        'clf__penalty': ('l1','l2'),\n",
    "        'clf__C': (2,3,4)}\n",
    "grid_search_lg = GridSearchCV(pipeline, parameters, cv = 3, return_train_score= True,n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                    multi_class='warn',\n",
       "                                                    n_jobs=None, penalty='l1',\n",
       "                                                    random_state=42,\n",
       "                                                    solver='warn', tol=0.0001,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),),\n",
       "                         'clf__C': (2, 3, 4), 'clf__penalty': ('l1', 'l2'),\n",
       "                         'vect__max_df': (0.4, 0.5),\n",
       "                         'vect__max_features': (8000, 9000),\n",
       "                         'vect__min_df': (6, 8),\n",
       "                         'vect__ngram_range': ((1, 2),)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                    random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'clf__C': 2,\n",
       " 'clf__penalty': 'l1',\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 9000,\n",
       " 'vect__min_df': 6,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929912132337775"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lg.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201616894901831"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lg.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = grid_search_lg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = grid_search_lg.best_estimator_['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9000)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = grid_search_lg.best_estimator_['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict={}\n",
    "for i, cls in enumerate(classes):\n",
    "    coef_dict[cls]=[]\n",
    "    for c, f in zip(coefs[i],featurenames):\n",
    "        if c:\n",
    "            coef_dict[cls].append((f,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('writeline', 34.35443542592411),\n",
       " ('net', 14.409952259671503),\n",
       " ('msdn', 13.406405098449603),\n",
       " ('ienumerable', 12.597638498674106),\n",
       " ('script jquery', 12.258235070200952),\n",
       " ('streamreader', 12.207305885657282),\n",
       " ('linq', 12.060271676062444),\n",
       " ('window form', 11.696983129235713),\n",
       " ('winforms', 11.34889725246229),\n",
       " ('entity framework', 11.139816376850316)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict['c#'],key=lambda x: x[1],reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('println', -29.522974297537914),\n",
       " ('django', -17.091895906609306),\n",
       " ('pythonic', -16.322255328863903),\n",
       " ('spring', -16.15729795551023),\n",
       " ('sun', -15.73658807129685),\n",
       " ('def', -15.077989494940644),\n",
       " ('jquery', -15.06177845407277),\n",
       " ('std', -13.810242160767265),\n",
       " ('gcc', -13.09393849381091),\n",
       " ('jvm', -12.65241004520841)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict['c#'],key=lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparmater for RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf',rf),\n",
    "])\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=800, num=10)]\n",
    "# Number of features to consider at every split\n",
    "mf = ['auto', 'sqrt']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10, 20, 30]\n",
    "max_df = np.linspace(0.3,0.75,num = 10)\n",
    "min_df = np.arange(1,16,2)\n",
    "max_features = np.arange(5000,10000,500)\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,1),(1,2)),\n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df':min_df,\n",
    "        'vect__max_features':max_features,\n",
    "        'clf': (rf,),\n",
    "        'clf__n_estimators': n_estimators,\n",
    "        'clf__max_features': mf,\n",
    "        'clf__min_samples_split': min_samples_split}\n",
    "clf_rf = RandomizedSearchCV(pipeline, parameters,random_state = 42, n_iter=100, cv = 3, n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           1),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop...\n",
       "                                                              400, 466, 533,\n",
       "                                                              600, 666, 733,\n",
       "                                                              800],\n",
       "                                        'vect__max_df': array([0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75]),\n",
       "                                        'vect__max_features': array([5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500]),\n",
       "                                        'vect__min_df': array([ 1,  3,  5,  7,  9, 11, 13, 15]),\n",
       "                                        'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900169134936677"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922785018973767"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__ngram_range': (1, 1),\n",
       " 'vect__min_df': 3,\n",
       " 'vect__max_features': 9000,\n",
       " 'vect__max_df': 0.6000000000000001,\n",
       " 'clf__n_estimators': 533,\n",
       " 'clf__min_samples_split': 30,\n",
       " 'clf__max_features': 'auto',\n",
       " 'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=30,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=533,\n",
       "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                        warm_start=False)}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer search\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', rf),\n",
    "])\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,1),),\n",
    "        'vect__max_df': (0.55,0.65),\n",
    "        'vect__min_df':(2,4),\n",
    "        'vect__max_features':(8500,9500),\n",
    "        'clf': (rf,),\n",
    "        'clf__n_estimators': (500,600),\n",
    "        'clf__min_samples_split': (25,35),\n",
    "        'clf__max_features':('auto',)}\n",
    "grid_search_rf = GridSearchCV(pipeline, parameters, cv = 3, return_train_score= True,n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                        n_jobs=None,\n",
       "                                                        oob_score=False,\n",
       "                                                        random_state=42,\n",
       "                                                        verbose=0,\n",
       "                                                        warm_start=False),),\n",
       "                         'clf__max_features': ('auto',),\n",
       "                         'clf__min_samples_split': (25, 35),\n",
       "                         'clf__n_estimators': (500, 600),\n",
       "                         'vect__max_df': (0.55, 0.65),\n",
       "                         'vect__max_features': (8500, 9500),\n",
       "                         'vect__min_df': (2, 4),\n",
       "                         'vect__ngram_range': ((1, 1),)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871704962666557"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922785018973767"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames_rf = grid_search_rf.best_estimator_['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_rf = grid_search_rf.best_estimator_['clf'].feature_importances_\n",
    "coef_f_rf =[]\n",
    "for c, f in zip(coefs_rf,featurenames_rf):\n",
    "        if c:\n",
    "            coef_f_rf.append((f,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jquery', 0.023405485148573425),\n",
       " ('var', 0.01950092964664314),\n",
       " ('function', 0.01671471717287409),\n",
       " ('std', 0.01641337512849392),\n",
       " ('net', 0.014702909481093665),\n",
       " ('def', 0.011136974370211484),\n",
       " ('public', 0.009981130643713813),\n",
       " ('browser', 0.009317913178577403),\n",
       " ('int', 0.00904948049191193),\n",
       " ('py', 0.008984148347329376),\n",
       " ('import', 0.008917878602245292),\n",
       " ('print', 0.007919087357927733),\n",
       " ('django', 0.007618115393399925),\n",
       " ('eclipse', 0.00761629081892026),\n",
       " ('html', 0.007360976468701237),\n",
       " ('page', 0.007088435804961556),\n",
       " ('println', 0.006406942238057315),\n",
       " ('div', 0.006234086421391037),\n",
       " ('class', 0.006119492042839767),\n",
       " ('new', 0.0058004493298996285)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_f_rf, key=lambda x: x[1], reverse = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multinominalNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "alpha =uniform(loc=0, scale=5)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(alpha = alpha)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf',nb),\n",
    "])\n",
    "max_df = np.linspace(0.3,0.75,num = 10)\n",
    "min_df = np.arange(1,16,2)\n",
    "max_features = np.arange(5000,10000,500)\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,1),(1,2)),\n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df':min_df,\n",
    "        'vect__max_features':max_features,\n",
    "        'clf': (nb,),\n",
    "        'clf__alpha':alpha\n",
    "            }\n",
    "clf_nb = RandomizedSearchCV(pipeline, parameters,random_state = 42, n_iter=100, cv = 3, n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           1),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop...\n",
       "                                        'clf__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1743535a20>,\n",
       "                                        'vect__max_df': array([0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75]),\n",
       "                                        'vect__max_features': array([5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500]),\n",
       "                                        'vect__min_df': array([ 1,  3,  5,  7,  9, 11, 13, 15]),\n",
       "                                        'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf_nb.best_estimator_['clf'].feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = clf_nb.best_estimator_['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = clf_nb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_nb={}\n",
    "for i, cls in enumerate(classes):\n",
    "    coef_dict_nb[cls]=[]\n",
    "    for c, f in zip(coefs[i],featurenames):\n",
    "        if c:\n",
    "            coef_dict_nb[cls].append((f,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('list', -5.176939563872745),\n",
       " ('file', -5.226266278864943),\n",
       " ('use', -5.241086563635494),\n",
       " ('print', -5.3348599109029715),\n",
       " ('py', -5.419126184945497),\n",
       " ('like', -5.454631833569824),\n",
       " ('way', -5.467000383963656),\n",
       " ('self', -5.524795070266238),\n",
       " ('import', -5.55602942455358),\n",
       " ('get', -5.584474875270401)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict_nb['python'], key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abstractautowirecapablebeanfactory', -11.832941267956661),\n",
       " ('accesscontroller', -11.832941267956661),\n",
       " ('accesscontroller doprivileged', -11.832941267956661),\n",
       " ('actionbar', -11.832941267956661),\n",
       " ('activitythread', -11.832941267956661),\n",
       " ('actor', -11.832941267956661),\n",
       " ('add subplot', -11.832941267956661),\n",
       " ('addclass', -11.832941267956661),\n",
       " ('adt', -11.832941267956661),\n",
       " ('alert hello', -11.832941267956661)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict_nb['c#'], key = lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultinomialNB(alpha=0.21801885877216876, class_prior=None, fit_prior=True),\n",
       " 'clf__alpha': 0.21801885877216876,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 7500,\n",
       " 'vect__min_df': 5,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566065756363186"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983831050981686"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer search\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf',nb),\n",
    "])\n",
    "parameters = {\n",
    "        'vect__ngram_range':((1,2),),\n",
    "        'vect__max_df': (0.45,0.55),\n",
    "        'vect__min_df':(4,6),\n",
    "        'vect__max_features':(7000,8000),\n",
    "        'clf': (nb,),\n",
    "        'clf__alpha': (0.2,0.3)}\n",
    "grid_search_nb = GridSearchCV(pipeline, parameters, cv = 3, return_train_score= True,n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=14,\n",
       "             param_grid={'clf': (MultinomialNB(alpha=0.2, class_prior=None,\n",
       "                                               fit_prior=True),),\n",
       "                         'clf__alpha': (0.2, 0.3), 'vect__max_df': (0.45, 0.55),\n",
       "                         'vect__max_features': (7000, 8000),\n",
       "                         'vect__min_df': (4, 6),\n",
       "                         'vect__ngram_range': ((1, 2),)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.55, max_features=8000,\n",
       "                                 min_df=6, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596180025576503"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799208051476654"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_nb = grid_search_nb.best_estimator_['clf'].feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames_nb = grid_search_nb.best_estimator_['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = grid_search_nb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_nb={}\n",
    "for i, cls in enumerate(classes):\n",
    "    coef_dict_nb[cls]=[]\n",
    "    for c, f in zip(coefs_nb[i],featurenames_nb):\n",
    "        if c:\n",
    "            coef_dict_nb[cls].append((f,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('function', -4.762648248036039),\n",
       " ('jquery', -5.0968846825146406),\n",
       " ('var', -5.12715526216715),\n",
       " ('use', -5.2164926284390285),\n",
       " ('div', -5.386255724526969),\n",
       " ('page', -5.453791435581551),\n",
       " ('html', -5.51520933477607),\n",
       " ('like', -5.527707844186999),\n",
       " ('script', -5.576720234298591),\n",
       " ('element', -5.663775381819082)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict_nb['javascript'], key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accesscontroller', -11.890707962913076),\n",
       " ('accesscontroller doprivileged', -11.890707962913076),\n",
       " ('activitythread', -11.890707962913076),\n",
       " ('actor', -11.890707962913076),\n",
       " ('add int', -11.890707962913076),\n",
       " ('add reference', -11.890707962913076),\n",
       " ('add subplot', -11.890707962913076),\n",
       " ('administrator', -11.890707962913076),\n",
       " ('adt', -11.890707962913076),\n",
       " ('aliasing', -11.890707962913076)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coef_dict_nb['javascript'], key = lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine results and do a majority vote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lg = grid_search_lg.predict(test_X)\n",
    "pred_rf = grid_search_rf.predict(test_X)\n",
    "pred_nb = grid_search_nb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = Counter([pred_lg[122],pred_rf[122], pred_nb[122]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java\n"
     ]
    }
   ],
   "source": [
    "for i,v in votes.items():\n",
    "    if votes[i]==max(votes.values()):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "predicted = zip(pred_lg,pred_rf,pred_nb)\n",
    "for p in predicted:\n",
    "    votes = Counter(p)\n",
    "    most = max(votes.values())\n",
    "    if most >1:\n",
    "        combined.append(list(votes.keys())[list(votes.values()).index(most)])\n",
    "    else:\n",
    "        combined.append(np.random.choice(list(votes.keys()),1)[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244514106583072"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y,combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1140,   29,  126,   73,   29],\n",
       "       [  48,  602,   78,   25,   23],\n",
       "       [ 102,   24, 1240,   66,   62],\n",
       "       [  53,    8,   56, 1227,   45],\n",
       "       [  48,   20,   96,   53,  788]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c#', 'c++', 'java', 'javascript', 'python'], dtype='<U10')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=9000,\n",
       "                                 min_df=6, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=2, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=42,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_lg','wb') as f:\n",
    "    pickle.dump(grid_search_lg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_lg','rb') as f:\n",
    "    t_lg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c#', 'c++', 'javascript', ..., 'c++', 'c#', 'javascript'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_lg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_rf','wb') as f:\n",
    "    pickle.dump(grid_search_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_rf','rb') as f:\n",
    "    t_rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c#', 'c++', 'javascript', ..., 'c#', 'c#', 'javascript'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_nb','wb') as f:\n",
    "    pickle.dump(grid_search_nb,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gs_nb','rb') as f:\n",
    "    t_nb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c#', 'c++', 'javascript', ..., 'c++', 'c#', 'javascript'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_nb.predict(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
